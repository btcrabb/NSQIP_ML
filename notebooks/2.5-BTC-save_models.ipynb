{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brend\\.conda\\envs\\NSQIP\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.6.10 |Anaconda, Inc.| (default, May  7 2020, 19:46:08) [MSC v.1916 64 bit (AMD64)]\n",
      "Pandas: 1.0.3\n",
      "Numpy: 1.18.1\n",
      "Sklearn: 0.22.1\n",
      "XGBoost: 1.1.1\n",
      "Keras: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define a random seed for reproducibility\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "import sklearn\n",
    "import xgboost\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "import os\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Pandas: {}'.format(pd.__version__))\n",
    "print('Numpy: {}'.format(np.__version__))\n",
    "print('Sklearn: {}'.format(sklearn.__version__))\n",
    "print('XGBoost: {}'.format(xgboost.__version__))\n",
    "print('Keras: {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_and_test(path):\n",
    "\n",
    "    \"\"\"Loads training features, training labels, testing features, and testing features\n",
    "    Parameters:\n",
    "        path (str) -- a single directory path containing all four datasets\n",
    "    \"\"\"\n",
    "\n",
    "    train_features = pd.read_csv(path + 'train_features.csv', index_col=0)\n",
    "    train_labels = pd.read_csv(path + 'train_labels.csv', index_col=0)\n",
    "    test_features = pd.read_csv(path + 'test_features.csv', index_col=0)\n",
    "    test_labels = pd.read_csv(path + 'test_labels.csv', index_col=0)\n",
    "\n",
    "    return train_features, train_labels.values.ravel(), test_features, test_labels.values.ravel()\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_train_and_test('../data/split/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a list of all optimization results files\n",
    "dirName = '../reports/optimization/'\n",
    "\n",
    "fileList = list()\n",
    "dirList = list()\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os. walk(dirName):\n",
    "    for file in filenames:\n",
    "        if '.csv' in file:\n",
    "            fileList.append(os.path. join(dirpath, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(name, hyperparameters):\n",
    "    \n",
    "    \"\"\" Loads the appropriate sklearn model from a model name and hyperparameters \"\"\"\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "    from sklearn.svm import SVC\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    if name == 'AdaBoost':\n",
    "        model = AdaBoostClassifier(**hyperparameters)\n",
    "    elif name == 'DecisionTree':\n",
    "        model = DecisionTreeClassifier(**hyperparameters)\n",
    "    elif name == 'KMeans':\n",
    "        model = KNeighborsClassifier(**hyperparameters)\n",
    "    elif name == 'MLP':\n",
    "        model = MLPClassifier(**hyperparameters)\n",
    "    elif name == 'RandomForest':\n",
    "        model = RandomForestClassifier(**hyperparameters)\n",
    "    elif name == 'SVC':\n",
    "        model = SVC(**hyperparameters, probability=True)\n",
    "    elif name == 'XGBoost':\n",
    "        model = XGBClassifier(**hyperparameters)\n",
    "    elif name == 'GradientBoosting':\n",
    "        model = GradientBoostingClassifier(**hyperparameters)\n",
    "    elif name == 'LogisticRegression':\n",
    "        model = LogisticRegression(**hyperparameters)\n",
    "    else:\n",
    "        print('Unkown model name')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../reports/optimization/AdaBoost\\2021-01-17_bayes_test.csv\n",
      "../reports/optimization/DecisionTree\\2021-01-17_bayes_test.csv\n",
      "../reports/optimization/GradientBoosting\\2021-01-17_bayes_test.csv\n",
      "../reports/optimization/LogisticRegression\\2021-01-17_bayes_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brend\\.conda\\envs\\NSQIP\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../reports/optimization/MLP\\2021-01-17_bayes_test.csv\n",
      "../reports/optimization/RandomForest\\2021-01-17_bayes_test.csv\n",
      "../reports/optimization/SVC\\2021-01-17_bayes_test.csv\n",
      "../reports/optimization/XGBoost\\2021-01-17_bayes_test.csv\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "for file in fileList:\n",
    "    #load hyperparameter optimization files\n",
    "    results = pd.read_csv(file)\n",
    "    \n",
    "    # find the model_name from the filename\n",
    "    file_split = file.split('/')[3]\n",
    "    model_name = file_split.split('\\\\')[0]\n",
    "    \n",
    "    print(file)\n",
    "\n",
    "    new_results = results.copy()\n",
    "\n",
    "    # String to dictionary\n",
    "    new_results['hyperparameters'] = new_results['hyperparameters'].map(ast.literal_eval)\n",
    "\n",
    "    # Sort with best values on top\n",
    "    new_results = new_results.sort_values('score', ascending = False).reset_index(drop = True)\n",
    "\n",
    "    # Use best hyperparameters to create a model\n",
    "    hyperparameters = new_results.loc[0, 'hyperparameters']\n",
    "    \n",
    "    # load the appropriate model and fit on training data\n",
    "    model = load_model(model_name, hyperparameters)\n",
    "    model.fit(X_train, Y_train)\n",
    "    \n",
    "    # create output filename\n",
    "    new_dir = '../models/'\n",
    "    filename = new_dir + model_name + '.sav'\n",
    "    \n",
    "    # save the trained model\n",
    "    pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NSQIP]",
   "language": "python",
   "name": "conda-env-NSQIP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
